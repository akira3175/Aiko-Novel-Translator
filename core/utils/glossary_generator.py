"""
Tá»± Ä‘á»™ng táº¡o glossary tá»« ná»™i dung chapters
"""
import re
from typing import List, Dict, Tuple
from django.db import transaction
from ..models import Novel, Chapter, Glossary
from .gemini_client import get_gemini_client
from google.genai import types


class GlossaryGenerator:
    """Táº¡o glossary tá»± Ä‘á»™ng tá»« chapters"""
    
    MAX_WORDS_PER_BATCH = 80000  # Má»—i batch tá»‘i Ä‘a 20k tá»«
    
    def __init__(self, novel: Novel):
        self.novel = novel
        self.client = get_gemini_client()
    
    @staticmethod
    def count_words(text: str) -> int:
        """Äáº¿m sá»‘ tá»« (kÃ½ tá»± HÃ¡n + tá»« Latin)"""
        chinese_chars = len(re.findall(r'[\u4e00-\u9fff]', text))
        other_words = len(re.findall(r'\b\w+\b', text))
        return chinese_chars + other_words
    
    def get_existing_glossary(self) -> str:
        """Láº¥y glossary hiá»‡n cÃ³ Ä‘á»ƒ tham kháº£o"""
        terms = self.novel.glossaries.all()
        if not terms:
            return ""
        
        lines = [f"{term.term_cn} = {term.term_vi}" for term in terms]
        return "\n".join(lines)
    
    def get_checkpoint(self) -> int:
        """
        Láº¥y vá»‹ trÃ­ checkpoint (chapter cuá»‘i cÃ¹ng Ä‘Ã£ xá»­ lÃ½)
        LÆ°u trong field description cá»§a novel
        """
        # Parse checkpoint tá»« description (format: "checkpoint:123")
        if self.novel.description:
            match = re.search(r'checkpoint:(\d+)', self.novel.description)
            if match:
                return int(match.group(1))
        return 0
    
    def save_checkpoint(self, chapter_index: int):
        """LÆ°u checkpoint vÃ o novel description"""
        if not self.novel.description:
            self.novel.description = f"checkpoint:{chapter_index}"
        else:
            # Replace existing checkpoint or append
            if 'checkpoint:' in self.novel.description:
                self.novel.description = re.sub(
                    r'checkpoint:\d+',
                    f'checkpoint:{chapter_index}',
                    self.novel.description
                )
            else:
                self.novel.description += f"\ncheckpoint:{chapter_index}"
        self.novel.save(update_fields=['description'])
    
    def batch_chapters(self, start_chapter: int = 0) -> List[List[Chapter]]:
        """
        Chia chapters thÃ nh cÃ¡c batch ~20k tá»«
        
        Args:
            start_chapter: Index chapter báº¯t Ä‘áº§u (0-based)
        
        Returns:
            List of chapter batches
        """
        all_chapters = []
        for volume in self.novel.volumes.all().order_by('index'):
            chapters = volume.chapters.filter(
                content_raw__isnull=False
            ).order_by('index')
            all_chapters.extend(chapters)
        
        # Skip Ä‘áº¿n start_chapter
        all_chapters = all_chapters[start_chapter:]
        
        batches = []
        current_batch = []
        current_word_count = 0
        
        for chapter in all_chapters:
            if not chapter.content_raw:
                continue
            
            chapter_words = self.count_words(chapter.content_raw)
            
            # Náº¿u thÃªm chapter nÃ y vÆ°á»£t quÃ¡ limit, lÆ°u batch hiá»‡n táº¡i
            if current_word_count + chapter_words > self.MAX_WORDS_PER_BATCH and current_batch:
                batches.append(current_batch)
                current_batch = [chapter]
                current_word_count = chapter_words
            else:
                current_batch.append(chapter)
                current_word_count += chapter_words
        
        # ThÃªm batch cuá»‘i
        if current_batch:
            batches.append(current_batch)
        
        return batches
    
    def extract_glossary_from_batch(
        self,
        chapters: List[Chapter],
        existing_glossary: str
    ) -> str:
        """Gá»i Gemini Ä‘á»ƒ trÃ­ch xuáº¥t glossary tá»« batch chapters"""
        
        # GhÃ©p ná»™i dung chapters
        content = "\n\n".join([
            f"=== {ch.title} ===\n{ch.content_raw}"
            for ch in chapters
            if ch.content_raw
        ])
        
        if not content.strip():
            return ""
        
        prompt = f"""
# ðŸ§™ Vai trÃ²
Báº¡n lÃ  **cÃ´ng cá»¥ há»— trá»£ dá»‹ch thuáº­t chuyÃªn cho truyá»‡n tiá»ƒu thuyáº¿t**.

---

# ðŸ§¾ Nhiá»‡m vá»¥
HÃ£y **trÃ­ch xuáº¥t vÃ  bá»• sung Báº¢NG THUáº¬T NGá»® (Glossary)** tá»« vÄƒn báº£n sau:

---
{content[:75000]}  
(... vÃ  cÃ¡c chÆ°Æ¡ng tiáº¿p theo)
---

---

# âš™ï¸ YÃªu cáº§u chi tiáº¿t

1. **TrÃ­ch xuáº¥t** táº¥t cáº£ cÃ¡c:
   - Thuáº­t ngá»¯ Ä‘áº·c biá»‡t
   - Danh hiá»‡u
   - XÆ°ng hÃ´
   - TÃªn riÃªng nhÃ¢n váº­t
   - Äá»‹a danh
   - Ká»¹ nÄƒng, chiÃªu thá»©c
   trong Ä‘oáº¡n vÄƒn á»Ÿ trÃªn.

2. **Bá» qua** nhá»¯ng tá»«:
   - Phá»• thÃ´ng, váº­t dá»¥ng Ä‘á»i thÆ°á»ng (vÃ­ dá»¥: æ‰‹æœº, æ¤…å­, å›¾ä¹¦é¦†â€¦)
   - Nghá» nghiá»‡p chung
   - Tá»« Ä‘Ã£ xuáº¥t hiá»‡n trong glossary cÅ© bÃªn dÆ°á»›i

3. **Chuyá»ƒn Ä‘á»•i vÃ  dá»‹ch:**
   - Náº¿u lÃ  **tÃªn riÃªng ngoáº¡i lai** (phiÃªn Ã¢m Trung, vÃ­ dá»¥: å¡æ´›æ–¯, èŽ‰äºš, äºšç‘Ÿ), 
     hÃ£y **chuyá»ƒn vá» dáº¡ng La-tinh gá»‘c** â†’ `å¡æ´›æ–¯ = Carlos`
   - Náº¿u lÃ  **thuáº­t ngá»¯, danh hiá»‡u, Ä‘á»‹a danh**, hÃ£y **dá»‹ch sang tiáº¿ng Viá»‡t tá»± nhiÃªn**.
   - Giá»¯ nháº¥t quÃ¡n vá»›i glossary cÅ©

---

## ðŸ“œ Glossary hiá»‡n cÃ³ (KHÃ”NG trÃ­ch xuáº¥t láº¡i):
{existing_glossary if existing_glossary else "ChÆ°a cÃ³"}

---

# âš ï¸ Äá»‹nh dáº¡ng Ä‘áº§u ra
> KhÃ´ng thÃªm chÃº thÃ­ch hay giáº£i thÃ­ch nÃ o khÃ¡c.  
> Chá»‰ xuáº¥t **thuáº§n vÄƒn báº£n**, má»—i dÃ²ng má»™t má»¥c, theo dáº¡ng:
åŽŸæ–‡ = Dá»‹ch

VÃ­ dá»¥:
æŽæ˜Ž = Li Minh
å‰‘åœ£ = Kiáº¿m ThÃ¡nh
"""

        try:
            response = self.client.models.generate_content(
                model="gemini-2.5-pro",
                contents=prompt,
                config=types.GenerateContentConfig(
                    temperature=0.3,
                )
            )
            
            return response.text.strip()
            
        except Exception as e:
            print(f"âš ï¸ Lá»—i khi táº¡o glossary: {e}")
            return ""
    
    def parse_and_save_glossary(self, glossary_text: str) -> int:
        """
        Parse glossary text vÃ  lÆ°u vÃ o database
        
        Returns:
            Sá»‘ terms má»›i Ä‘Æ°á»£c thÃªm
        """
        if not glossary_text.strip():
            return 0
        
        lines = glossary_text.strip().split('\n')
        new_count = 0
        
        with transaction.atomic():
            for line in lines:
                line = line.strip()
                if not line or '=' not in line:
                    continue
                
                # Parse: åŽŸæ–‡ = Dá»‹ch
                parts = line.split('=', 1)
                if len(parts) != 2:
                    continue
                
                term_cn = parts[0].strip()
                term_vi = parts[1].strip()
                
                if not term_cn or not term_vi:
                    continue
                
                # Táº¡o hoáº·c update
                _, created = Glossary.objects.get_or_create(
                    novel=self.novel,
                    term_cn=term_cn,
                    defaults={'term_vi': term_vi}
                )
                
                if created:
                    new_count += 1
        
        return new_count
    
    def generate(self, start_from_checkpoint: bool = True) -> Dict:
        """
        Cháº¡y quy trÃ¬nh táº¡o glossary
        
        Args:
            start_from_checkpoint: Tiáº¿p tá»¥c tá»« checkpoint hay báº¯t Ä‘áº§u tá»« Ä‘áº§u
        
        Returns:
            Dict vá»›i thÃ´ng tin tá»•ng káº¿t
        """
        # Láº¥y checkpoint
        start_chapter = self.get_checkpoint() if start_from_checkpoint else 0
        
        print(f"ðŸ“š Báº¯t Ä‘áº§u táº¡o glossary cho: {self.novel.title}")
        print(f"ðŸ“ Checkpoint: Chapter {start_chapter}")
        
        # Láº¥y glossary hiá»‡n cÃ³
        existing_glossary = self.get_existing_glossary()
        print(f"ðŸ“– Glossary hiá»‡n cÃ³: {self.novel.glossaries.count()} terms")
        
        # Chia batches
        batches = self.batch_chapters(start_chapter)
        print(f"ðŸ“¦ Tá»•ng sá»‘ batches: {len(batches)}")
        
        total_new_terms = 0
        processed_chapters = 0
        
        for i, batch in enumerate(batches, 1):
            print(f"\nâ–¶ Batch {i}/{len(batches)}: {len(batch)} chapters")
            
            # TÃ­nh word count
            word_count = sum(self.count_words(ch.content_raw or '') for ch in batch)
            print(f"   ðŸ“Š ~{word_count:,} tá»«")
            
            # TrÃ­ch xuáº¥t glossary
            glossary_text = self.extract_glossary_from_batch(batch, existing_glossary)
            
            # Parse vÃ  lÆ°u
            new_terms = self.parse_and_save_glossary(glossary_text)
            total_new_terms += new_terms
            
            print(f"   âœ… ThÃªm {new_terms} terms má»›i")
            
            # Cáº­p nháº­t existing glossary
            existing_glossary = self.get_existing_glossary()
            
            # LÆ°u checkpoint (chapter cuá»‘i cá»§a batch)
            last_chapter = batch[-1]
            chapter_index = self._get_chapter_global_index(last_chapter)
            self.save_checkpoint(chapter_index)
            processed_chapters += len(batch)
            
            print(f"   ðŸ’¾ Checkpoint saved: Chapter {chapter_index}")
        
        summary = {
            'total_batches': len(batches),
            'processed_chapters': processed_chapters,
            'new_terms': total_new_terms,
            'total_terms': self.novel.glossaries.count(),
            'checkpoint': self.get_checkpoint()
        }
        
        print(f"\nðŸŽ‰ HoÃ n táº¥t!")
        print(f"ðŸ“Š Tá»•ng káº¿t:")
        print(f"   - ÄÃ£ xá»­ lÃ½: {processed_chapters} chapters")
        print(f"   - Terms má»›i: {total_new_terms}")
        print(f"   - Tá»•ng terms: {summary['total_terms']}")
        
        return summary
    
    def _get_chapter_global_index(self, chapter: Chapter) -> int:
        """Láº¥y index global cá»§a chapter (qua táº¥t cáº£ volumes)"""
        count = 0
        for volume in self.novel.volumes.all().order_by('index'):
            if volume.index < chapter.volume.index:
                count += volume.chapters.count()
            elif volume.index == chapter.volume.index:
                count += chapter.index
                break
        return count